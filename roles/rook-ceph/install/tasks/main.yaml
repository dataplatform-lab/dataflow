- name: Add Rook-Ceph chart repository
  kubernetes.core.helm_repository:
    name: rook-ceph
    repo_url: https://charts.rook.io/release

- name: Install Rook-Ceph Operator
  kubernetes.core.helm:
    name: rook-ceph
    chart_ref: rook-ceph/rook-ceph
    chart_version: "{{ rook_ceph_operator_version }}"
    create_namespace: true
    release_namespace: "{{ rook_ceph_namespace }}"
    values:
      crds:
        enabled: true
      logLevel: "{{ rook_log_level }}"
      enableDiscoveryDaemon: true
      discoveryDaemonInterval: 60m
      operatorMetricsBindAddress: "{{ rook_operator_metrics_bind_address }}"
      cephAllowLoopDevices: "{{ rook_ceph_allow_loop_devices }}"
      useCSIOperator: "{{ rook_use_csi_operator }}"
      csi:
        enableRbdDriver: "{{ csi_enable_rbd_driver }}"
        enableCephfsDriver: "{{ csi_enable_cephfs_driver }}"
        enableCSIHostNetwork: false
        enableCephfsSnapshotter: "{{ csi_enable_cephfs_snapshotter }}"
        enableNFSSnapshotter: "{{ csi_enable_nfs_snapshotter }}"
        enableRBDSnapshotter: "{{ csi_enable_rbd_snapshotter }}"
        enablePluginSelinuxHostMount: "{{ csi_plugin_selinux_host_mount }}"
        enableCSIEncryption: "{{ csi_encryption_enabled }}"
        provisionerReplicas: "{{ csi_provisioner_replicas }}"
        clusterName: "{{ rook_ceph_cluster_name }}"
        resources: "{{ csi_resources }}"
        serviceMonitor:
          enabled: false
        csiAddons:
          enabled: false
        nfs:
          enabled: false
        topology:
          enabled: false
        cephFSAttachRequired: false
        rbdAttachRequired: false
        nfsAttachRequired: false
      monitoring:
        enabled: "{{ monitoring_enabled }}"

- name: Install Rook-Ceph Cluster
  kubernetes.core.helm:
    name: rook-ceph-cluster
    chart_ref: rook-ceph/rook-ceph-cluster
    chart_version: "{{ rook_ceph_cluster_version }}"
    release_namespace: "{{ rook_ceph_namespace }}"
    values:
      operatorNamespace: "{{ rook_ceph_namespace }}"
      clusterName: "{{ rook_ceph_cluster_name }}"
      configOverride: |
        [global]
        mon_allow_pool_delete = true
        osd_pool_default_size = {{ ceph_config_global_osd_pool_default_size | default(3) }}
        osd_pool_default_min_size = {{ ceph_config_global_osd_pool_default_min_size | default(2) }}
        mon_warn_on_pool_no_redundancy = {{ ceph_config_global_mon_warn_on_pool_no_redundancy | default(true) }}
        bdev_flock_retry = {{ ceph_config_global_bdev_flock_retry | default(3) }}
        bluefs_buffered_io = {{ ceph_config_global_bluefs_buffered_io | default(true) }}
        mon_data_avail_warn = {{ ceph_config_global_mon_data_avail_warn | default(15) }}

        [client.rgw.{{ objectstore_name }}.a]
        rgw_allow_notification_secrets_in_cleartext = true
      toolbox:
        enabled: "{{ toolbox_enabled }}"
        replicas: "{{ toolbox_replicas }}"
        image: "{{ toolbox_image }}"
        imagePullPolicy: "{{ toolbox_image_pull_policy }}"
        dnsPolicy: "{{ toolbox_dns_policy }}"
        serviceAccountName: "{{ toolbox_service_account_name }}"
        securityContext: "{{ toolbox_security_context }}"
        tolerations: "{{ toolbox_tolerations }}"
      monitoring:
        enabled: "{{ monitoring_enabled }}"
      cephClusterSpec:
        cephVersion:
          image: "{{ ceph_image }}"
          allowUnsupported: true
        dataDirHostPath: /var/lib/rook
        skipUpgradeChecks: "{{ skip_upgrade_checks }}"
        mon:
          count: "{{ mon_count | default(3) }}"
          allowMultiplePerNode: "{{ mon_allow_multiple_per_node | default(false) }}"
        mgr:
          count: "{{ mgr_count | default(2) }}"
          allowMultiplePerNode: "{{ mgr_allow_multiple_per_node | default(false) }}"
          modules:
            - name: rook
              enabled: true
        dashboard:
          enabled: "{{ dashboard_enabled }}"
          ssl: "{{ dashboard_ssl }}"
          prometheusEndpoint: "{{ prometheus_endpoint if prometheus_endpoint | length > 0 else omit }}"
          prometheusEndpointSSLVerify: false
        network:
          connections:
            encryption:
              enabled: "{{ network_encryption_enabled | default(true) }}"
            compression:
              enabled: "{{ network_compression_enabled | default(true) }}"
            requireMsgr2: "{{ network_require_msgr2 | default(true) }}"
        crashCollector:
          disable: "{{ crash_collector_disable | default(false) }}"
          daysToRetain: 30
        logCollector:
          enabled: false
        cleanupPolicy:
          confirmation: ""
        removeOSDsIfOutAndSafeToRemove: false
        healthCheck:
          daemonHealth:
            mon:
              interval: "{{ health_check_daemon_health_mon_interval | default('45s') }}"
              timeout: "{{ health_check_daemon_health_mon_timeout | default('25s') }}"
        priorityClassNames:
          all: "{{ priority_class_names_all }}"
          mgr: "{{ priority_class_names_mgr }}"
        disruptionManagement:
          managePodBudgets: "{{ disruption_management_manage_pod_budgets | default(true) }}"
        storage:
          useAllNodes: "{{ storage_use_all_nodes | default(true) }}"
          useAllDevices: "{{ storage_use_all_devices | default(false) }}"
          allowDeviceClassUpdate: "{{ storage_allow_device_class_update | default(true) }}"
          allowOsdCrushWeightUpdate: "{{ storage_allow_osd_crush_weight_update | default(true) }}"
      cephObjectStores:
        - name: "{{ objectstore_name }}"
          spec:
            metadataPool:
              failureDomain: host
              replicated:
                size: { { objectstore_metadata_pool_size | default(3) } }
                requireSafeReplicaSize: true
            dataPool:
              failureDomain: host
              replicated:
                size: { { objectstore_data_pool_size | default(3) } }
                requireSafeReplicaSize: true
            preservePoolsOnDelete: true
            gateway:
              port: "{{ objectstore_gateway_port }}"
              resources: "{{ objectstore_resources }}"
              instances: "{{ objectstore_instances | default(2) }}"
          storageClass:
            enabled: "{{ objectstore_storage_class_enabled }}"
            name: "{{ objectstore_storage_class_name }}"
            reclaimPolicy: "{{ objectstore_storage_class_reclaim_policy }}"
            volumeBindingMode: "{{ objectstore_storage_class_volume_binding_mode }}"
            parameters:
              region: ap-northeast-2
      cephBlockPools:
        - name: builtin-mgr
          spec:
            name: .mgr
            replicated:
              size: { { mgr_pool_size | default(3) } }
              requireSafeReplicaSize: true
          storageClass:
            enabled: false
      cephFileSystems: []
      cephFileSystemVolumeSnapshotClass:
        enabled: false
      cephBlockPoolsVolumeSnapshotClass:
        enabled: false

- name: Create Ceph Dashboard Service
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: v1
      kind: Service
      metadata:
        name: rook-ceph-mgr-dashboard-external
        namespace: "{{ rook_ceph_namespace }}"
        labels:
          app: rook-ceph-mgr
          rook_cluster: "{{ rook_ceph_cluster_name }}"
      spec:
        type: LoadBalancer
        ports:
          - name: dashboard
            port: 7000
            protocol: TCP
            targetPort: 7000
        selector:
          app: rook-ceph-mgr
          rook_cluster: "{{ rook_ceph_cluster_name }}"
          mgr_role: active
  when: dashboard_enabled | bool

- name: Create Ceph Object Store Service
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: v1
      kind: Service
      metadata:
        name: rook-ceph-rgw-{{ objectstore_name }}-external
        namespace: "{{ rook_ceph_namespace }}"
        labels:
          app: rook-ceph-rgw
          rook_cluster: "{{ rook_ceph_cluster_name }}"
      spec:
        type: LoadBalancer
        ports:
          - name: http
            port: 80
            protocol: TCP
            targetPort: 8080
        selector:
          app: rook-ceph-rgw
          ceph_daemon_id: "{{ objectstore_name }}"
          rgw: "{{ objectstore_name }}"
          rook_cluster: "{{ rook_ceph_cluster_name }}"
          rook_object_store: "{{ objectstore_name }}"

- name: Wait for Rook-Ceph Operator to be ready
  kubernetes.core.k8s_info:
    kind: Deployment
    name: rook-ceph-operator
    namespace: "{{ rook_ceph_namespace }}"
  register: operator_status
  until: >
    operator_status.resources | length > 0 and
    operator_status.resources[0].status is defined and
    operator_status.resources[0].status.readyReplicas is defined and
    operator_status.resources[0].status.replicas is defined and
    operator_status.resources[0].status.readyReplicas == operator_status.resources[0].status.replicas
  retries: 30
  delay: 10

- name: Wait for Ceph Cluster to be ready
  kubernetes.core.k8s_info:
    kind: CephCluster
    name: "{{ rook_ceph_cluster_name }}"
    namespace: "{{ rook_ceph_namespace }}"
  register: cluster_status
  until: >
    cluster_status.resources | length > 0 and
    cluster_status.resources[0].status is defined and
    cluster_status.resources[0].status.phase is defined and
    cluster_status.resources[0].status.phase == "Ready"
  retries: 60
  delay: 30

- name: Create Ceph Object Store User (admin)
  kubernetes.core.k8s:
    state: present
    definition:
      apiVersion: ceph.rook.io/v1
      kind: CephObjectStoreUser
      metadata:
        name: admin
        namespace: "{{ rook_ceph_namespace }}"
      spec:
        store: "{{ objectstore_name }}"
        displayName: "admin"
  when: objectstore_storage_class_enabled | bool
